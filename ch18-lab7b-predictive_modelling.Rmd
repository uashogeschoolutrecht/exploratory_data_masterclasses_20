# Lab 6d - Predictive modelling {#lab6d-predictive-modelling}

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      warning = FALSE,
                      error = FALSE,
                      message = FALSE, 
                      cache = TRUE,
                      fig.width = 6, fig.height = 5)
```


Here we will use a classic case example "The Titanic Dataset"
after:

https://tylerburleigh.com/blog/surviving-the-titanic-with-r-caret/ and 

https://www.kaggle.com/swamysm/beginners-titanic


and information about building models with `{caret}`: https://www.machinelearningplus.com/machine-learning/caret-package/#35howtopreprocesstotransformthedata

To illustrate how we can combine EDA with a predictive modelling strategy we will look at the famous Titanic dataset for the next part of this chapter.

Usually building a predictive model exists of several steps, most commonly in this order:

 1. Data load
 1. Inspect and clean the data
 1. Exploratory Data Analysis to find interesting features and provide leads for 'feature engineering'
 1. Feature engineering; The process where you dive into the data to extract additonal features, accumulate levels into groups or remove data that provides no information
 1. Preprocessing; The data needs te be in a specific format and variables are usually scaled, centered and categorical variables are transformed to dummy variables
 1. Splitting the data into a training, a validation and a test set
 1. Defining the model, the method for cross-validation, the number of iterations and the actual machine learning algorithm(s) to use.
 1. Usually after a first model, the model needs to be tuned to prevent 'overfitting'
 1. Testing the model on the test set to evaluate the model's performance
 1. When the model is meant for predictions in a production environment it needs te be deployed
 1. One a model is deployed the work for the data scientist is not over because each model needs to be eva;uated in production and it's preformance needs to be monitored
 1. During the evalaution phase the model can be tweaked and tuned even further  to increase it's perfomance, while trying to prevent it form overfitting.
 1 ...
 
I will illustrate each step below using the famous 'Titanic' dataset from KAGGLE. First we will explore the Titanic dataset to get an idea on what data we have, than do some feature engineering, build and tune a model and test the resulting model on a test subset of the data. 

**The thing you need to take away from this exercise/demo is that it is most important to never ever let your models be exposed to data from the test set, before it it time to test the model**. 

The problems that arise when you omit to take this rule into account are comparable to insider trading. In most cases it will not put you in jail, but it could...

### <mark>**EXERCISE 1; Getting the Titanic data**</mark> {-}

```{r}
## a few prerequisites for the Titanic demo
library(tidyverse)
library(caret)
library(ranger) # Faster RF modeling
library(wru) # Bayesian prediction of ethnicity

# Setup parallel processing
suppressWarnings(suppressMessages(library(parallel)))
suppressWarnings(suppressMessages(library(doParallel)))
cluster <- makeCluster(detectCores() - 1) # convention to leave 1 core for OS
registerDoParallel(cluster)

# Custom function
`%not in%` <- function (x, table) is.na(match(x, table, nomatch=NA_integer_))

# Random seed
set.seed(43287)

```

The data for this demo can be obtained from KAGGLE (you will need to log in)
Download and inspect the data from [here](https://www.kaggle.com/c/titanic)
After log-in to KAGGLE, choose the 'download all' button.

Another way to directly access the KAGGLE API from R is with the `{kaggler}` package. We will not use it here because you need to get an API token and fix some settings to use it. If you plan to use KAGGLE a lot for your learning or to join in the compettions, it might be worthwhile to look at: https://github.com/mkearney/kaggler  

The data dictionary can be found here: https://www.kaggle.com/c/titanic/data

In short:

|Variable   |	Definition  |	Key                                           |
|---------  |-------------|-----------------------------------------------|
|PassengerId| unique id   |                                               |  
|Survived   | Survival  | 0 = No, 1 = Yes                                 |
|Pclass 	  | Ticket class | 	1 = 1st, 2 = 2nd, 3 = 3rd                   |
|Name       | The title, Surname (Family name) and Given name (First name)||
|Sex        | Sex       |                                                 |
|Age        | Age in years | 	                                            |
|SibSp      | # of siblings / spouses aboard the Titanic|                 |	
|Parch      | # of parents / children aboard the Titanic| 	              |
|Ticket     | Ticket number |                                             | 	
|Fare       | Passenger fare |                                            |	
|Cabin      | Cabin number |                                              |
|Embarked   | Port of Embarkation |	C = Cherbourg, Q = Queenstown, S = Southampton|

A) Download the Titanic data and load it into R: 

 1. Download the zip archive from KAGGLE
 1. unzip the file in the "./data" folder
 1. Load the 'test.csv' and the 'train.csv' into R. Call the datasets `test` and `train`, respectively. 
 1. Change the `Survived` variable in the `train` dataframe to a factor

```{r, include=FALSE}
## unzip zipfile with 'unzip()'
# Load data
test <- read_csv(
  here::here(
  "data",  
  "test.csv"),
  col_types = 
  cols(
  PassengerId = col_integer(),
  Pclass = col_factor(),
  Name = col_character(),
  Sex = col_factor(),
  Age = col_double(),
  SibSp = col_double(),
  Parch = col_double(),
  Ticket = col_character(),
  Fare = col_double(),
  Cabin = col_character(),
  Embarked = col_character()
))


test

train <- read_csv(
  here::here(
  "data",
  "train.csv"),
   col_types = 
  cols(
  Survived = col_character(),  
  PassengerId = col_integer(),
  Pclass = col_factor(),
  Name = col_character(),
  Sex = col_factor(),
  Age = col_double(),
  SibSp = col_double(),
  Parch = col_double(),
  Ticket = col_character(),
  Fare = col_double(),
  Cabin = col_character(),
  Embarked = col_character()
  )) %>%  # `Survived` needs to be a true factor variable
  dplyr::mutate(Survived = ifelse(Survived == 0, "No", "Yes"),
                Survived = as_factor(Survived))

train
names(test) ## there is no 'Survided' in the test set
names(train)
```

B) Assess the amount of missingness in the train and test datasets. Use the functions from the `{naniar}` package.

 1. Which variable(s) have missingness? 
 1. How could you deal with this?

```{r, include=FALSE}
test %>%
  naniar::vis_miss() +
  ggtitle("Missiness test")

train %>%
  naniar::vis_miss() +
  ggtitle("Missiness train")

```

C) Exploratory data analysis
Generate a number of exploratory graphs that tell you something about the relationship between some of the predictors (Class, Age, Sex, Fare etc.) and the `Survived` variable. We do the EDA only on the train dataset
What are your conclusions?

```{r, include=FALSE}
train %>%
  ggplot(aes(x = Sex)) +
  geom_histogram(aes(fill = Survived), 
                 stat = "count",
                 position = "dodge") 

train %>%
  ggplot(aes(x = Pclass)) +
  geom_histogram(aes(fill = Survived), 
                 stat = "count",
                 position = "dodge") 

train %>%
  ggplot(aes(x = log10(Fare))) +
  geom_density(aes(colour = Survived), size = 1) 

train %>%
  ggplot(aes(x = Age)) +
  geom_density(aes(colour = Survived), size = 1) 
```

D) From the exploratory graphs, can you make out which predictors are most promising to use in a predictive model?

E) Try making sense of the `Name` variable. What type of information is hidden in this variable? How would you get it out? try Google ;-). Write a few lines of pseudocode to extract the information you think if valuable.
```{r, include=FALSE}
train$Name[1:5]
```

--- END EXERCISE ---

## Check variables in train and test
```{r}
names(train) %in% names(test) ## so `Survided` is the only variable missing
```

### <mark>**EXERCISE 2; EDA packages in R**</mark> {-} 
There are many specialized EDA packages in R. One that has a nice vignette and comprehensive functionality that integrates smoothly with the tidyverse is the `{dlookr}` package. We explore its functionallity further here.

A) Using the examples in the `{dlookr}` vignette: get the decriptive statitistics for the continuous variables in the Titanic `train` data
```{r, include=FALSE}
#install.packages("dlookr")
library(dlookr)

# pastecs::stat.desc()

descriptives_train <- train %>%
  describe()

```

B) Using the `dlookr::plot_correlate()` function, create a correlation matrix.
```{r, include=FALSE}
plot_correlate(train)
```

C) Expand on the correlation matrix including the `Survided` variable
```{r, include=FALSE}
train %>%
  group_by(Survived) %>%
  plot_correlate()
```

What can you conclude?

--- EXERCISE END ---

## Now let's focus on the `Name` variable
The Titanic data contains the variable `Name`. Normally you would expect such a variable to be a low or non-variance variable, assuming that each individual has a unique name, or that there is some duplication but very little. This would mean that this variable does not hold any information for grouping datapoints. This type of variable is called a zero-variance or zero-to-low information variable. However, in this case, the person's titles are encapsulated within the `Name` variable and as it turns out these titles hold valuable information as they are a proxy for socio-economical class. This could be related to the chance of survival of the Titanic disaster as we will see later. Below we see the first five entries in `Name` as they appear in the train data.   

```{r}
train$Name[1:5]
```

Below we 'feature engineer' the `Name` variable to extract valuable information on the titles etc. Go over the code step by step to see if you understand what is goin on. Here we see the use of `->` at the end of a pipe (`%>%`). This makes sense if you have a long pipe that ends in the creation of an R-object. I've included it here for demo puposes.

### Engeneering the `Name` {-}
```{r}
## clean up the Name variable
train %>%
  rowwise %>%
  mutate(title = gsub('(.*, )|(\\..*)', '', Name)) -> train

train$title[1:5]

train %>%
  ggplot(., aes(x = title, fill=Survived)) + 
  geom_bar(position = "dodge") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) + 
  ggtitle("Survival by titles")

# Special titles
train %>%
  dplyr::filter(title %not in% c("Mr", "Ms", "Mrs", "Miss", "Master")) %>%
  ggplot(., aes(title, fill=Survived)) + 
  geom_bar() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) + 
  ggtitle("Survival by special titles by sex") + facet_wrap(~ Sex)

```

In the next step 'Master' and 'Miss' are renamed to 'Boy' and 'Girl' and a few other title classes are defined. Special is reserved for 'special' titles: Capt", "Don", "Col", "Major", "Dr", "Rev", "Dona", "Jonkheer", "the Countess", "Lady", "Sir", which could hold valuable socio-economical information that relates to survival.  
```{r}
train %>%
  mutate(child = ifelse(Age < 15, 1, 0),
         title.class = case_when(
            title %in% c("Master") ~ "Boy",
            title %in% c("Miss") & child == 1 ~ "Girl",
            title %in% c("Mrs") ~ "Woman",
            title %in% c("Miss", "Mme", "Mlle", "Ms") ~ "Lady",
            title %in% c("Dr") & Sex == "female" ~ "Woman",
            title %in% c("Mr") ~ "Man",
            title %in% c("Capt", "Don", "Col", "Major", "Dr", "Rev", 
                         "Dona", "Jonkheer", "the Countess", "Lady", "Sir") ~ "Special",
            TRUE ~ "Other")) -> train

```


### <mark>**EXERCISE 3; Explore the `title_class` variable**</mark>

Here we explore the `title.class` variable in relation to other variables and to `Survived`

A) Create a number of exploratory graphs that display the realtionships between `title.class`, `Sex`, `Survived` and `Pclass`

```{r, include=FALSE}
train %>% 
  group_by(title.class, Survived) %>%
  tally() %>%
  arrange(n)

train %>%
  ggplot(aes(x=title.class, fill=Survived)) + 
  geom_bar(position = "dodge") + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) + 
  ggtitle("Survival by title and sex")

train %>%
  ggplot(aes(x=title.class, fill=Survived)) + 
  geom_bar(position = "dodge") + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) + 
  ggtitle("Survival by title and Pclass") + 
  facet_wrap(~ Pclass)


total_died <- train %>%
  dplyr::filter(Survived == "No") %>%
  nrow

train %>% 
  dplyr::filter(Survived == "No") %>%
  group_by(title.class, Pclass, Survived) %>%
  tally() %>%
  arrange(desc(n, Pclass)) %>%
  mutate(percentage.died = 100*(n/total_died)) %>%
  ggplot(aes(x  = reorder(as_factor(title.class), percentage.died), 
             y = percentage.died)) +
  geom_col(aes(fill = as_factor(Pclass)), position = "dodge") +
  xlab(NULL)

```

B) What is your conclusion from the graphs under A)?
```{r, include=FALSE}
##What stands out is that >50% of the people that did not survive were men travelling with titanic in third class cabins.
```

--- END EXERCISE ---

## Family size
Is the size of the family a determining factor for survival? `SibSp` and `Parch` are variables that determines the size of 'the family' on board of the Titanic.   

```{r}
## Family size
## Combine SibSp and Parch into a single “family size” variable.

train %>%
  mutate(family.size = SibSp + Parch,
         family.size.simple = case_when(
            family.size == 0 ~ "0",
            between(family.size, 1, 3) ~ "1-3",
            family.size > 3 ~ ">3")) -> train

## get different family sizes present in the data
train$family.size %>% unique()

train %>%
  ggplot(., aes(family.size)) +
  geom_histogram(bins=30)

train %>% ungroup %>% count(family.size.simple)

train %>%
  ggplot(., aes(family.size, fill=Survived)) + 
  geom_bar() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) + 
  ggtitle("Survival by family size and sex") + facet_wrap(~ Sex)

train %>%
  ggplot(., aes(family.size, fill=Survived)) + 
  geom_bar() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) + 
  ggtitle("Survival by family size and sex") + facet_wrap(~ title.class)

train %>%
  ggplot(., aes(family.size.simple, fill=Survived)) + 
  geom_bar() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) + 
  ggtitle("Survival by family size and sex") + facet_wrap(~ Sex)

train %>%
  ggplot(., aes(family.size.simple, fill=Survived)) + 
  geom_bar() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) + 
  ggtitle("Survival by family size and Pclass") + facet_wrap(~ Pclass)

```

## Did being a man of lower class, travelling alone by yourself get you killed on Titanic?

From the variable notes

pclass: A proxy for socio-economic status (SES)
1st = Upper
2nd = Middle
3rd = Lower

age: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5

sibsp: The dataset defines family relations in this way:
Sibling = brother, sister, stepbrother, stepsister
Spouse = husband, wife (mistresses and fiancés were ignored)

parch: The dataset defines family relations in this way:
Parent = mother, father
Child = daughter, son, stepdaughter, stepson
Some children travelled only with a nanny, therefore parch=0 for them.

So yes, about 300 casualties (about ~54% of all deads) were lower class men, travelling alone.


## Let's look at the amount of money paid for a ticket (`Fare` variable)

```{r}
train %>%
  ggplot(., aes(Fare)) +
  geom_histogram(bins=30)

train %>%
  rowwise %>%
  mutate(Fare.grps = case_when(
            between(Fare, 0, 100) ~ "0-100",
            Fare > 100 ~ ">100")) -> train

train %>%
  ggplot(., aes(Fare.grps, fill=Survived)) + 
  geom_bar() + 
  ggtitle("Survival by fare groups and class") + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  facet_wrap(~Pclass)

train %>% ungroup %>% count(Fare.grps)
```

## Pclass
The `Pclass` variable can be regarded as a proxy for socio-economical class. 1 is higher class (more expensive ticket), 2 is middle class, (somewhat cheaper) and 3 is lower class (cheap ticket).

```{r}
train %>%
  ggplot(., aes(as.numeric(Pclass), fill=Survived)) + 
  geom_bar() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) + 
  ggtitle("Survival by passenger class") +
  xlab("PClass")

class(train$Pclass)
levels(train$Pclass)



```

## <mark>**EXERCISE 4; Some additional feature engineering**</mark>

Run the following code chunk and look at the output carefully. Try to follow all steps and explain for yourself what each step does. Comment each block with a short comment.

```{r}
train %>%
  ggplot(., aes(Age)) +
  geom_histogram(bins=30)

train %>%
  mutate(Age.grps = case_when(
            between(Age, 0, 12) ~ "young",
            between(Age, 12, 50) ~ "middle",
            Age > 50 ~ "old")) -> train

train %>% ungroup %>% count(Age.grps)

train %>%
  ggplot(., aes(Age.grps, fill=Survived)) + 
  geom_bar() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) + 
  ggtitle("Age groups survival by Pclass") + facet_wrap(~ Pclass)

train %>%
  ggplot(., aes(Age.grps, fill=Survived)) + 
  geom_bar() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) + 
  ggtitle("Age groups survival by Sex") + facet_wrap(~ Sex)

train %>%
  ggplot(., aes(Age.grps, fill=Survived)) + 
  geom_bar() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) + 
  ggtitle("Age groups survival by Sex and Pclass") + facet_wrap(~ Sex*Pclass)

train %>%
    rowwise %>%
    mutate(ticket.prefix = ifelse(grepl(" ", Ticket), sub(" .*", "", Ticket), ""),
           ticket.prefix = toupper(gsub("(\\.)|(\\/)", "", ticket.prefix)),
           ticket.prefix = case_when(
            ticket.prefix == "STONO" ~ "SOTONO",
            ticket.prefix == "STONO2" ~ "SOTONO",
            ticket.prefix == "SOTONOQ" ~ "SOTONO",
            ticket.prefix == "SOTONO2" ~ "SOTONO",
            ticket.prefix == "SCAH" ~ "SCA",
            ticket.prefix == "SCA4" ~ "SCA",
            ticket.prefix == "PPP" ~ "PP",
            ticket.prefix == "CASOTON" ~ "CA",
            ticket.prefix == "AS" ~ "A",
            ticket.prefix == "A4" ~ "A",
            ticket.prefix == "A5" ~ "A",
            ticket.prefix == "SOP" ~ "SOPP",
            ticket.prefix == "SWPP" ~ "",
            ticket.prefix == "FA" ~ "",
            TRUE ~ ticket.prefix)) -> train

train %>%
  ggplot(., aes(ticket.prefix, fill=Survived)) + 
  geom_bar() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) + 
  ggtitle("Survival by ticket prefix") +
  coord_flip()

train %>%
    rowwise %>%
    mutate(surname = gsub('( .*)|(*,*)', '', Name)) -> train

train$surname[1:5]

library(wru)
wru::predict_race(train, surname.only = TRUE) -> train

train %>%
  rowwise %>%
  mutate(race = case_when(
            pred.whi == max(pred.whi, pred.bla, pred.his, pred.asi, pred.oth) ~ "White",
            TRUE ~ "Non-White"
          )) ->train

train %>%
  ggplot(., aes(race, fill=Survived)) + 
  geom_bar() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) + 
  ggtitle("Survival by race and sex") + facet_wrap(~ Sex)
```

### <mark>**EXERCISE 5; Features**</mark> {-} 

A) We cannot use the `all.died` and `dead.family` variables for predictive modelling, why not?

## Models

Adapted from: https://tylerburleigh.com/blog/surviving-the-titanic-with-r-caret/

Now it time to start thinking about buillding predictive models, ....

But first we apply all transformations and feature engineering that we did above to the test data. 

```{r}
#test %>% 
#  mutate(Fare = ifelse(PassengerId == 1044, 
#                       median((test %>% filter(!is.na(Fare), 
#                                               Pclass == 3, 
#                                               PassengerId != 1044))$Fare), Fare)) -> test.final

test %>%
  rowwise %>%
  mutate(title = gsub('(.*, )|(\\..*)', '', Name),
         child = ifelse(Age < 15, 1, 0),
         title.class = case_when(
            title %in% c("Master") ~ "Boy",
            title %in% c("Miss") & child == 1 ~ "Girl",
            title %in% c("Mrs") ~ "Woman",
            title %in% c("Miss", "Mme", "Mlle", "Ms") ~ "Lady",
            title %in% c("Dr") & Sex == "female" ~ "Woman",
            title %in% c("Mr") ~ "Man",
            title %in% c("Capt", "Don", "Col", "Major", "Dr", "Rev", 
                         "Dona", "Jonkheer", "the Countess", "Lady", "Sir") ~ "Special",
            TRUE ~ "Other"),
         family.size = SibSp + Parch,
         family.size.simple = case_when(
            family.size == 0 ~ "0",
            between(family.size, 1, 3) ~ "1-3",
            family.size > 3 ~ ">3"
          ),
         Fare.grps = case_when(
            between(Fare, 0, 100) ~ "0-100",
            Fare > 100 ~ ">100",
          ),
         Age.grps = case_when(
            between(Age, 0, 12) ~ "young",
            between(Age, 12, 50) ~ "middle",
            Age > 50 ~ "old"
          ),
         ticket.prefix = ifelse(grepl(" ", Ticket), sub(" .*", "", Ticket), ""),
         ticket.prefix = toupper(gsub("(\\.)|(\\/)", "", ticket.prefix)),
           ticket.prefix = case_when(
            ticket.prefix == "STONO" ~ "SOTONO",
            ticket.prefix == "STONOQ" ~ "SOTONO",
            ticket.prefix == "STONO2" ~ "SOTONO",
            ticket.prefix == "SOTONOQ" ~ "SOTONO",
            ticket.prefix == "SOTONO2" ~ "SOTONO",
            ticket.prefix == "SCAH" ~ "SCA",
            ticket.prefix == "SCA4" ~ "SCA",
            ticket.prefix == "SCA3" ~ "SCA",
            ticket.prefix == "PPP" ~ "PP",
            ticket.prefix == "CASOTON" ~ "CA",
            ticket.prefix == "AS" ~ "A",
            ticket.prefix == "A4" ~ "A",
            ticket.prefix == "A5" ~ "A",
            ticket.prefix == "SOP" ~ "SOPP",
            ticket.prefix == "SWPP" ~ "",
            ticket.prefix == "FA" ~ "",
            ticket.prefix == "AQ3" ~ "",
            ticket.prefix == "AQ4" ~ "",
            ticket.prefix == "LP" ~ "",
            TRUE ~ ticket.prefix),
         surname = gsub('( .*)|(*,*)', '', Name)) -> test.final

# Ethnicity
predict_race(test.final, surname.only = TRUE) -> test.final

test.final %>%
  rowwise %>%
  mutate(race = case_when(
            pred.whi == max(pred.whi, pred.bla, pred.his, pred.asi, pred.oth) ~ "White",
            TRUE ~ "Non-White")) -> test.final

```

## Check features present in train and test
```{r}
names(train)
names(test.final)

names(test.final) %in% names(train)

ind <- names(train) %in% names(test.final)
names(train)[!ind] ## `Survived` is the only feature not present in test.final, sound like logic to me ... 
```

## Now it is time to preprocess the data for modelling

### Impute missing values

We see some missingness in the `Fare` and a lot in the `Age` variable in `test` and missingness for `Age` only in `train`. Here is how to impute those missing values: The values for `Fare` that are missing are imputed on the basis of the values for `Pclass`, `Sex`, `Age`, `Ticket`, `SibSp`, `Embarked` and `Parch`, assumes a relationship between these variables and `Fare`. we use the `train` dataset to impute the `Fare` values in `test`. Be sure to use the `train` imputation model on the `test` set. The models you create may never be exposed to any data of the test set.
What do you think about these assumptions?

We cannot impute the missingness for the `Cabin` variable, why?

```{r}
library(caret)
# copy train for later
train.final <- train
# Impute missing ages in Training data
train.final %>% dplyr::select(
 Age,
   Sex,
   Fare,
   Pclass,
   family.size) -> train.impute
pre.proc <- preProcess(train.impute, method = "bagImpute")
train.impute <- predict(pre.proc, train.impute)
train.final$Age <- train.impute$Age
naniar::vis_miss(train.final)

# impute test, using the imputation model of train!
test.final %>% dplyr::select(
   Age,
   Sex,
   Fare,
   Pclass,
   family.size) -> test.impute

naniar::vis_miss(test.impute)
test.impute <- predict(pre.proc, newdata = test.impute)

naniar::vis_miss(test.impute)
test.final$Age <- test.impute$Age
test.final$Fare <- test.impute$Fare
# check imputation
naniar::vis_miss(train.final)
naniar::vis_miss(test.final)


```

### Select features {-}

First step in the modelling process is to select those variables that are promosing features as identified from the EDA steps. 
For sake of clarity, I will use the original train and test set as supplied by KAGGLE. So we leave the feature engeering part behind and only use the the orignal supplied datsets for now. You can alway come back to this code and try to improve youpredictions by ading more 'engineered' variables. Don't forget, whatever engineering you do on the train dataset has to be somehow also transferred to the test data. This can be difficult.

For modelling a dependent y with predictors xi we can write the following pseudoformula:

$ yi = xia + xib + xic + xi... + \epsilon$

In R, y needs to be a factor, we use `as_factor` to achieve this.
We remove `Cabin` and `PassengerId` from `train` and `test` and convert the coding of `Survived` to something more meaningful: 0 = "No", 1 = "Yes".

```{r}
train.final %>%
  dplyr::select(
   Survived,
   Sex,
   Pclass,
   Age,
   SibSp,
   Parch,
   Fare,
   title.class,
   family.size,
   pred.whi,
   pred.bla,
   pred.his,
   pred.asi,
   pred.oth,
   race) -> train.final.selection

train.final %>% naniar::vis_miss()

test.final %>%
  dplyr::select(
   Sex,
   Pclass,
   Age,
   SibSp,
   Parch,
   Fare,
   title.class,
   family.size,
   pred.whi,
   pred.bla,
   pred.his,
   pred.asi,
   pred.oth,
   race
    ) -> test.final.selection

test.final %>% naniar::vis_miss()
```

### Create dummy variables

Second step is to convert all categorical variables in the data to so-called dummy variables.
Here a short conceptual example
```{r}
not_dummy <- tribble(
  ~species, ~offspring, ~litter_size,
  "dog", "puppy", 4,
  "cat", "kitten", 5,
  "cow", "calf", 1
)
not_dummy

# store y
y <- not_dummy$species

# One-Hot Encoding
# Creating dummy variables is converting a categorical variable to as many binary variables as here are categories.
dummies_model <- dummyVars(species ~ ., data = not_dummy, fullRank = TRUE)

# Create the dummy variables using predict. The Y variable (Purchase) will not be present in trainData_mat.
dummy_mat <- predict(dummies_model, newdata = not_dummy)

# Convert to dataframe
dummy_df <- as_tibble(dummy_mat)

# add y back to df
dummy_df$species <- y
dummy_df



```
 
We apply the above example method to the Titanic `train_final` dataframe. Because `test_final` has no `Survived` we cannot use the `caret` method.

```{r}
y_titanic <- train.final.selection$Survived 
train_dummy_model <- dummyVars(Survived ~ ., 
                               data = train.final.selection, 
                               fullRank = TRUE) 
train_mat <- predict(train_dummy_model, 
                     newdata = train.final.selection)

# Convert to dataframe
train_dummy_final <- as_tibble(train_mat)

# add y back to df
train_dummy_final$Survived <- y_titanic
train_dummy_final

## create dummy vars for Titanic test 
## create fake `Survived`
test.final.selection$Survived <- "Yes"
test_dummy_mat <- predict(train_dummy_model, 
                     newdata = test.final.selection)

test_dummy_final <- as_tibble(test_dummy_mat) 
test_dummy_final
```

Third step preprocess, scale values to min = 0 and max = 1
```{r}
pre_process_range_model <- preProcess(train_dummy_final, method='range')

train_dummy_preprocessed_final <- predict(
  pre_process_range_model, newdata = train_dummy_final
  )

# Append the Y variable
train_dummy_preprocessed_final$Survived <- y_titanic

test_dummy_prepocessed_final <- predict(
  pre_process_range_model, newdata = test_dummy_final
)


test_dummy_preprocessed_final <- as_tibble(
  test_dummy_prepocessed_final
)

test_dummy_prepocessed_final
## leave out y (becasue this is a factor) %>%
map_df(train_dummy_preprocessed_final[, -20], .f=function(x){c('min'=min(x, na.rm = TRUE), 'max'=max(x, na.rm = TRUE))})  

train_dummy_preprocessed_final %>%
  gather(Sex.female:raceWhite, key = "predictor", value = "value") %>%    
ggplot(aes(x = predictor, y = value)) +
  geom_point(aes(colour = Survived), alpha  = 0.6, shape = 1) + 
  coord_flip()

test_dummy_preprocessed_final %>%
  gather(Sex.female:raceWhite, key = "predictor", value = "value") %>%    
ggplot(aes(x = predictor, y = value)) +
  geom_point(alpha  = 0.6, shape = 1) + 
  coord_flip()

```

Fourth step in the modelling proces is to split the data into:

 1. A training set to learn the model about patterns in the data
 1. A validation set, to test the performace of the model
 1. A test set, or so called hold-out to evaluate the models true performance on never-before-seen data

```{r} 
# For Cross validation purpose will keep 20% of data aside from my orginal train set
# This is just to check how well my model works for unseen data
set.seed(500)
ind = createDataPartition(train_dummy_preprocessed_final$Survived, 
                          times = 1, 
                          p = 0.8,
                          list=FALSE)

train_val = train_dummy_preprocessed_final[ind,] %>% as_tibble()
test_val = train_dummy_preprocessed_final[-ind,] %>% as_tibble()

####check the proportion of Survival rate in orginal training data, current traing and testing data
round(
  prop.table(
    table(
      train_dummy_preprocessed_final$Survived
      )
    *100),
  digits = 1
  )
round(
  prop.table(
    table(
      train_val$Survived)
    *100),
  digits = 1
  )
round(
  prop.table(
    table(
      test_val$Survived)
    *100),
  digits = 1
  )


```

## Feature importance
```{r}
library(caret)
library(rpart)
#install.packages("rpart.plot")
library(rpart.plot)
##Random forest is for more better than Single tree however single tree is very easy to use and illustrate
set.seed(1234)
regression_tree = rpart(
  Survived~. , 
  data = train_val, method="class"
  )


rpart.plot(
  regression_tree,
  extra = 1,
  fallen.leaves = TRUE
  )

## single tree
predict_regression_tree = predict(
  regression_tree, data = train_val, type="class"
  )

confusionMatrix(predict_regression_tree,train_val$Survived)

```

## Using FeaturePlot
```{r}
featurePlot(x = train_val[, c(1:19)], 
            y = train_val$Survived, 
            plot = "box",
            strip=strip.custom(par.strip.text=list(cex=.7)),
            scales = list(x = list(relation="free"), 
                          y = list(relation="free")))
```

## Recursive Feature Elimination of RFE
```{r}
set.seed(100)
options(warn=-1)

subsets <- c(1:5, 10, 15, 18, 22, 41)

ctrl <- rfeControl(functions = rfFuncs,
                   method = "repeatedcv",
                   repeats = 5,
                   verbose = FALSE)

train_val_noNA <- train_val %>% na.omit() 

lmProfile <- rfe(x=train_val_noNA[, c(1:19)], 
                 y=train_val_noNA$Survived,
                 sizes = subsets,
                 rfeControl = ctrl, 
                 verbose = TRUE)

lmProfile

```

## Train three models for comparison

 1. Decision tree, variant of random forest `method = "rpart"` via the `caret` API. 
 1. RandomForest algorithm: `method = "rf"` 
 1. Boosting: `method = "xgbDART"`

For each model we create 10 validation folds (iterations). Because missing values can cause problems I remove the two rows having missing values in the train set. The dataframe we use for training is called `train_val_noNA`

How does regression tree work:
```{r}
knitr::include_graphics(
  here::here(
    "images",
    "regression_tree_split.png"
  )
)
```

### Decision trees: "rpart" {-}
```{r, cache=TRUE}
set.seed(1234)
cv.10 <- createMultiFolds(train_val$Survived, k = 10, times = 10)

# Control
ctrl <- trainControl(method = "repeatedcv", 
                     number = 10, repeats = 10,
                     index = cv.10,
                     verboseIter = TRUE)


##Train the model
model_rpart <- train(
  x = train_val[, c(1:19)], ## exclude y `Survided`  
  y = train_val$Survived,  ## include only y
  method = "rpart",
  tuneLength = 30,
  trControl = ctrl)

model_rpart %>% plot
model_rpart

# check the variable imporatnce, is it the same as in Single tree?
rpart.plot(model_rpart$finalModel,extra =  4,fallen.leaves = T)

# test model on test data
rpart_prediction <- predict(object = model_rpart, 
                              newdata = test_val) 

caret::confusionMatrix(data = rpart_prediction,         
                        reference = test_val$Survived)


```

### RandomForest: "rf"
```{r, cache=TRUE, eval=FALSE}
set.seed(1234)

##Train the model
model_rf <- train(
  x = train_val_noNA[, c(1:19)], ## exclude y `Survided`  
  y = train_val_noNA$Survived,  ## include only y
  method = "rf",
  tuneLength = 30,
  trControl = ctrl)

model_rf %>% plot
model_rf

## feature importance
var_imp_rf <- varImp(model_rf)
var_imp_rf$importance
## pot importance features
plot(var_imp_rf, top = 8)

# test model on test data
rf_prediction <- predict(object = model_rf, 
                              newdata = test_val) 

caret::confusionMatrix(data = rf_prediction,         
                        reference = test_val$Survived)


```

### Boosting; a RandomForest tree regression method with *turbo* "xgbDART" {-}

**This algorithm takes a long time to compute**
```{r, cache=TRUE, eval=FALSE}
set.seed(1234)
cv.10 <- createMultiFolds(train_val$Survived, k = 10, times = 10) ## reduce number of iterations, for computing speed

# Control
#ctrl <- trainControl(method = "repeatedcv", 
#                     number = 4, repeats = 4,
#                     index = cv.10,
#                     verboseIter = TRUE,
#                     allowParallel = TRUE)
##Train the model
model_xgb <- train(
  x = train_val[, c(1:19)], ## exclude y `Survided`  
  y = train_val$Survived,  ## include only y
  method = "xgbDART",
  tuneLength = 30,
  trControl = ctrl
  )

model_xgb %>% plot

model_xgb


# test model on test data
xgb_prediction <- predict(object = model_xgb, 
                              newdata = test_val) 



caret::confusionMatrix(data = rf_prediction,         
                        reference = test_val$Survived)


```

## Predicting the unseen `test_dummy_preprocessed_final` dataset to submit to Kaggle

Remember that we already imputed the `the `test` dataset  and created dummy variables. 
```{r, eval=FALSE}
## rpart
rpart_prediction <- predict(
  object = model_rpart, 
  newdata = test_dummy_prepocessed_final) 

rpart_prediction_df <- rpart_prediction %>%
  enframe() %>%
  mutate(Survived = ifelse(value == "No", 0, 1),
         PassengerId = test$PassengerId) %>%
  select(PassengerId, Survived)

write_csv(rpart_prediction_df, 
          path = 
            here::here(
            "data",
            "rpart_predictions_kaggle_titanic.csv")
          )

## "rf" predictions
rf_prediction <- predict(
  object = model_rf, 
  newdata = test_dummy_prepocessed_final) 


rf_prediction_df <- rf_prediction %>%
  enframe() %>%
  mutate(Survived = ifelse(value == "No", 0, 1),
         PassengerId = test$PassengerId) %>%
  select(PassengerId, Survived)

write_csv(rpart_prediction_df, 
          path = 
            here::here(
            "data",
            "rf_predictions_kaggle_titanic.csv")
          )


## xgboost for comparison
xgb_prediction <- predict(
  object = model_xgb, 
  newdata = test_dummy_prepocessed_final) 

xgb_prediction_df <- xgb_prediction %>%
  enframe() %>%
  mutate(Survived = ifelse(value == "No", 0, 1),
         PassengerId = test$PassengerId) %>%
  select(PassengerId, Survived)

write_csv(xgb_prediction_df, 
          path = 
            here::here(
            "data",
            "xgb_predictions_kaggle_titanic.csv")
          )


```

Submitting these predictions to KAGGLE yields a somewhat disappointing result, but not bad for a first try ...
```{r}
knitr::include_graphics(
  here::here(
    "images",
    "titanic_scores.jpg"
  )
)
```


## Hyperparamter tuning
Overfitting of a predictive algorithm is always a challenge in  building a relevant model for real-life purposes. Above we implicitly tuned the model by using the build in `{caret}` function `trainControl()`. It takes a lot of practice and study to be able to build a fully tuned model. This is out of scope of this course. [To learn more:](https://www.machinelearningplus.com/machine-learning/caret-package/#35howtopreprocesstotransformthedata)    


### <mark>**EXERCISE 6; OPEN EXERCISE - NO ANSWER AVAILABLE**</mark> {-}

 1. Create a plot using the `Sacramento` dataframe, showing the relationship between the variables `type`, `sqft` and `price`. Consider price to be the dependent variable that should go on the y-axis. The rest of the plot is up to you.
 1. Create the same graph as above but now log10-transform the `price` variable
 1. Now add facets to accomodate the variables `baths` and `beds`
 1. Create a summary tables that displays the amount of observations for each level in the factor variable `type`,
 1. What can you conclude from this exploration? Write a short statement.
 1. How would you predict the price, using other variables in 'Sacramento'. Write a code chunk to get started. Write peusocode and then translate the code to real R code. Build 1 model: what is the accuracy of your prediction model?
 1. Which feature in your prediction model has the highest importance, create a plot

## Further reading and additional tips to integrate modelling with tidyverse tools: Out-of-scope for the course

A modern way in R to do preprocessing and modelling of data is through the combination with:

 - `{recipes}`
 - `{parsnip}`
 - `{tidymodels}`

These three packages are build to work with all the `{tidyverse}` tools you have learned about so far. One of the developers of these packages is Max Kuhn, the author of the famous predictive modelling package `{caret}`.

The code below was taken from: https://github.com/tidymodels/parsnip 
https://tidymodels.github.io/parsnip/articles/parsnip_Intro.html

## Recipes

A _recipe_ can be trained then applied to any data. 

```{r rec_basic}
library(recipes) 
library(dplyr)
library(caret)
data("Sacramento")

## Create an initial recipe with only predictors and outcome
rec <- recipe(price ~ type + sqft, data = Sacramento)
rec <- rec %>% 
  step_log(price) %>%
  step_dummy(type, one_hot = TRUE)
rec_trained <- prep(rec, training = Sacramento, retain = TRUE)
design_mat <- bake(rec_trained, new_data = Sacramento)
design_mat
```

```{r, include=FALSE}

## 1.
Sacramento %>%
  ggplot(aes(x = sqft,
             y = price)) +
  geom_point(aes(colour = type), alpha = 0.3)  +
  guides(colour = guide_legend(override.aes = list(alpha = 1)))

## 2.
Sacramento %>%
  ggplot(aes(x = sqft,
             y = log10(price))) +
  geom_point(aes(colour = type), alpha = 0.3)

## 3.
Sacramento %>%
  ggplot(aes(x = sqft,
             y = log10(price))) +
  geom_point(aes(colour = type), alpha = 0.3) +
  facet_grid(beds ~ baths)

## 4.
## summary
Sacramento %>%
  dplyr::group_by(type) %>%
  tally()


```

### Include the log transofrmation step in the recipe
```{r}
rec <- recipe(price ~ type + sqft, data = Sacramento)
rec <- rec %>% 
  step_log(price) %>%
  step_dummy(type, one_hot = TRUE) %>%
  step_log(price)
 
rec_trained <- prep(rec, training = Sacramento, retain = TRUE)
design_mat <- bake(rec_trained, new_data = Sacramento)
design_mat

```

## We can explore this data with Principal Component Analysis
The steps to perform preprocessing, fitting and prediction are:

 1. Build a recipe
 1. Use `prep()` to prepare the recipe
 1. `bake()` the preparation
 1. Use `predict()` to predict 'new' or 'test' data

```{r}
rec <- recipe(~ ., data = Sacramento)
pca_trans <- rec %>%
  step_center(all_numeric()) %>%
  step_scale(all_numeric()) %>%
  step_pca(all_numeric(), num_comp = 3)
pca_estimates <- prep(pca_trans, training = Sacramento)

##
pca_data <- bake(pca_estimates, Sacramento)


pca_data %>%
  ggplot(aes(x = PC1,
             y = PC2)) +
  geom_point(aes(colour = Sacramento$type), alpha = 0.4)

pca_data %>%
  ggplot(aes(x = PC1,
             y = PC3)) +
  geom_point(aes(colour = Sacramento$type), alpha = 0.4)

pca_data %>%
  ggplot(aes(x = PC2,
             y = PC3)) +
  geom_point(aes(colour = Sacramento$type), alpha = 0.4)

```

### Creating models with `{parsnip}`

The idea of parsnip is to:

 - Separate the definition of a model from its evaluation.
 - Decouple the model specification from the implementation (whether the implementation is in R, spark, or something else). For example, the user would call rand_forest instead of ranger::ranger or other specific packages.
 - Harmonize the argument names (e.g. n.trees, ntrees, trees) so that users can remember a single name. This will help across model types too so that trees will be the same argument across random forest as well as boosting or bagging.

### Let's look at linear regression first
Here we use mtcars for simplicity
```{r}

library(parsnip)
names(mtcars)

mtcars %>%
  ggplot(aes(x = disp,
             y = mpg)) +
  geom_point()


norm_recipe <- 
  recipe(
    mpg ~ disp, 
    data = mtcars) %>% 
  # estimate the means and standard deviations
  prep(training = mtcars, retain = TRUE)


lin_reg <- parsnip::linear_reg(mode = "regression") %>%
  set_engine("lm") %>%
  fit(mpg ~ disp, data = mtcars) %>%
  broom::tidy()

lin_reg   

## plot the line in the scatterplot
mtcars %>%
  ggplot(aes(x = disp,
             y = mpg)) +
  geom_point() +
  geom_abline(intercept = lin_reg$estimate[1],
              slope = lin_reg$estimate[2])

```

### Extending the regression with more predictors
```{r}
norm_recipe_multiple <- 
  recipe(
    mpg ~ ., 
    data = mtcars) %>% 
  # estimate the means and standard deviations
  prep(training = mtcars, retain = TRUE)

lin_reg_multiple <- linear_reg(mode = "regression") %>%
  set_engine("lm") %>%
  fit(mpg ~ ., data = mtcars) 

lin_reg_multiple %>%
  broom::tidy()


## plot the line in the scatterplot
mtcars %>%
  ggplot(aes(x = wt,
             y = mpg)) +
  geom_point() +
  geom_abline()

mtcars %>%
  ggplot(aes(x = drat,
             y = mpg)) +
  geom_point() +
  geom_abline()


```

### Predict mpg from a number of observations
We create a split of the original data (20% test set, 80% training)
```{r}
library(rsample)

cars_split <- initial_split(mtcars)
cars_train <- training(cars_split)
cars_test <- testing(cars_split)

## to prevent 'leakage of test data into the training set, we apply the recipe to the training set only
norm_recipe_train <- 
  recipe(
    mpg ~ ., 
    data = cars_train) %>% 
  # estimate the means and standard deviations
  prep(training = cars_train, retain = TRUE)

lin_reg_train <- linear_reg(mode = "regression") %>%
  set_engine("lm") %>%
  fit(mpg ~ ., data = juice(norm_recipe_train)) 


preds <- predict(object = lin_reg_train, new_data = cars_test)

## check performance
validate <- dplyr::bind_cols(mpg_original = cars_test$mpg, 
                             predictions = preds$.pred)

validate %>%
  ggplot(aes(x = mpg_original,
             predictions)) +
  geom_point() +
  geom_abline(slope = 1, intercept = 0)
```

### Can we improve with another fit?
```{r}

rand_forest_fit <- rand_forest(mode = "regression") %>%
  set_engine("ranger") %>%
  fit(mpg ~ ., data = juice(norm_recipe_train)) 

rand_forest_fit

preds <- predict(object = rand_forest_fit, new_data = cars_test)

## check performance
validate <- dplyr::bind_cols(mpg_original = cars_test$mpg, 
                             predictions = preds$.pred)

validate %>%
  ggplot(aes(x = mpg_original,
             predictions)) +
  geom_point() +
  geom_abline(slope = 1, intercept = 0)


```

### General linear model vs Random Forest to make predictions and learn about the data
Here we use the Ames Housing data 

```{r}
library(AmesHousing)
ames <- make_ames()

library(tidymodels)

set.seed(4595)
## use stratification
data_split <- initial_split(ames, strata = "Sale_Price", p = 0.75)

ames_train <- training(data_split)
ames_test  <- testing(data_split)

```

### Random Forests
```{r}
rf_defaults <- rand_forest(mode = "regression")
rf_defaults

## using the formula approach
rand_forest(mode = "regression", mtry = 3, trees = 1000) %>%
  set_engine("ranger") %>%
  fit(
    log10(Sale_Price) ~ Longitude + Latitude + Lot_Area + Neighborhood + Year_Sold,
    data = ames_train
  )
```

### Penalized Logistic Regression

A linear model might work here too. The linear_reg model can be used. To use regularization/penalization, there are two engines that can do that here: the glmnet and sparklyr packages. The former will be used here and it only implements the non-formula method. parsnip will allow either to be used though.

When regularization is used, the predictors should first be centered and scaled before given to the model. The formula method won’t do that so some other methods will be required. We’ll use recipes package for that (more information here).

```{r}

norm_recipe <- 
  recipe(
    Sale_Price ~ Longitude + Latitude + Lot_Area + Neighborhood + Year_Sold, 
    data = ames_train
  ) %>%
  step_other(Neighborhood) %>% 
  step_dummy(all_nominal()) %>%
  step_center(all_predictors()) %>%
  step_scale(all_predictors()) %>%
  step_log(Sale_Price, base = 10) %>% 
  # estimate the means and standard deviations
  prep(training = ames_train, retain = TRUE)

# Now let's fit the model using the processed version of the data

glmn_fit <- 
  linear_reg(penalty = 0.001, mixture = 0.5) %>% 
  set_engine("glmnet") %>%
  fit(Sale_Price ~ ., data = juice(norm_recipe))


glmn_fit


test_normalized <- bake(norm_recipe, new_data = ames_test, all_predictors())

pred <- predict(glmn_fit, new_data = test_normalized) 

results <- dplyr::bind_cols(ames_test, pred)
names(results)
results %>%
  ggplot(aes(x = Sale_Price, y = .pred)) +
  geom_point()

```

### Let's look at the effect of centering and scaling with a Principal Component Analysis:
```{r}

iris_pca <- function(center, scale){

data(iris)
iris <- tibble::as_tibble(iris)
log_iris <- log(iris[, 1:4]) ## only numeric variables can be used for PCA
iris_species <- iris[, 5] ## labels

iris_pca <- stats::prcomp(log_iris,
                   center = center,
                   scale = scale) 

plot <- as_tibble(iris_pca$x) %>%
  mutate(description = iris_species$Species) %>%

  ggplot(aes(x = PC1, y = PC2, color = description)) +
  geom_point() +
  theme_bw() 

return(plot)

}

iris_pca(scale = FALSE, center = FALSE)
iris_pca(scale = TRUE, center = TRUE)

```

## Using Box-Cox transformations
In order to spead up the process of finding the right transformation we can preform a Box-Cox transformation which will yield us a lambda value. Below I who an example. From [@apm]
The estimated paramter in the Box-Cox transformation is Lambda.

Below are examples of how λ is implemented for a transformation on predictor variablel Y

Lambda value (λ) | Transformed data (Y’)
---------------------------------------
-3 	             | \[Y^{-3} = 1/Y^{3}\]
-2 	             | \[Y^{-2} = 1/Y^{2}\]
-1 	             | \[Y^{-1} = 1/Y^{1}\]
-0.5 	           | \[Y^{-0.5} = 1/(√Y)\]
etc.


```{r}
library(AppliedPredictiveModeling)
data(segmentationOriginal)
segmentationOriginal %>% as_tibble()

## Retain the original training set
segTrain <- subset(segmentationOriginal, Case == "Train")

## Remove the first three columns (identifier columns)
segTrainX <- segTrain[, -(1:3)]
segTrainClass <- segTrain$Class

## difference between max an minimal value (cutoff 20x)
max(segTrainX$VarIntenCh3)/min(segTrainX$VarIntenCh3)

## Use caret's preProcess function to transform for skewness
segPP <- preProcess(segTrainX, method = "BoxCox")

## Apply the transformations
segTrainTrans <- predict(segPP, segTrainX)

## Results for a single predictor
segPP$bc$VarIntenCh3

histogram(~segTrainX$VarIntenCh3,
          xlab = "Natural Units",
          type = "count")

histogram(~log(segTrainX$VarIntenCh3),
          xlab = "Log Units",
          ylab = " ",
          type = "count")
```

## To learn more:

https://github.com/topepo/AppliedPredictiveModeling 
and:

```{r, eval=FALSE}
learnr::run_tutorial("adventr_log", package = "adventr")
```
